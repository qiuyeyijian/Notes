

## 研究现状

随着物联网领域进一步发展，在边缘执行尽可能多的处理，逐渐出现一种需求，即在直接位于或附着于传感器上的微控制器上执行推理。也就是说，微处理器中应用处理器和神经网络加速器的发展速度十分迅猛，更完善的解决方案也层出不穷。总体趋势是将更多以人工智能为中心的功能（例如神经网络处理）与应用处理器一起整合到微处理器中，同时避免功耗或尺寸显著增加。

如今，可以先在功能更强大的CPU或GPU上训练模型，然后在使用推理引擎（例如TensorFlow Lite）的微控制器上实施，从而减小尺寸以满足微控制器的资源要求。可轻松扩展，以适应更高的ML要求。相信不久之后，推理和训练就能在这些设备上同时执行，让微控制器的竞争力直追更大、更昂贵的计算解决方案。

http://www.chinaem.com.cn/News.aspx?newsid=2813





这两者都还处于实验阶段，还没有跑起来MobileNet等大家耳熟能详的轻量级网络，能跑的只是MNIST或者Cifar10等级的教学意义上的小网络，没有任何的意义，并且它们对要求使用者具有丰富的神经网络经验，包括但不限于：量化，剪枝，蒸馏，压缩。这些都大大限制了它的实用性。





> 按新出的“Edge AI”的概念，传感器除了能够测量，还必须能够识别自己测量的是什么东西。它需要依靠自己的能力去消化原始数据，而不是将一大堆原始数据丢给云计算。神经网络分类器是一个效果很好的动作识别工具，缺点是计算量太大。就算在学术界都很少有人把它直接放到MCU上跑，工程上可能更少。通常认为MCU资源太少，性能太弱跑不了神经网络。但是我不这么认为，我觉得性能低的MCU自然有计算量少一些的神经网络与之相配，小模型不过是准确率低一些。而且，2014年之后的神经网络的发展方向更多的是往模型的结构优化上做文章，同时还更注重效能上的优化而不是识别精度。于是性能弱鸡的MCU有了发挥的空间。2018年12月，搜了一圈后（并没有合适的），我决定还是自己写一个,也是为了让MCU这个真正的edge设备也神经一把。 - 转载请保留原文链接：https://www.kaifa5.com/12398.html



一颗简单的MCU，让深度学习在网络边缘上跑起来

https://www.eefocus.com/mcu-dsp/473608



MCU集成人工智能，要靠它了

https://www.163.com/dy/article/H1T7VUOQ05521T32.html





在边缘实现机器学习都需要什么？

https://www.infoq.cn/article/shdudgbwmho0ewwpmk5i
