

## 设备

STM32L431RCT

带FPU的超低功耗80 Mhz Arm Cortex-M4 MCU

|        属性        |     参数值     |      |
| :----------------: | :------------: | :--: |
|      商品目录      | ST(意法半导体) |      |
|     主频（MAX)     |     80MHz      |      |
|      工作电压      |  1.71V ~ 3.6V  |      |
|      ROM尺寸       |     256KB      |      |
|      RAM大小       |      64KB      |      |
|       I/O 数       |       52       |      |
|        A/D         |    16x12bit    |      |
|        D/A         |    2x12bit     |      |
|        PWM         |       1        |      |
|     UART/USART     | 3 USART+1 UART |      |
|        SPI         |       3        |      |
| I2C（SMBUS/PMBUS） |       3        |      |
|        CAN         |       1        |      |
|      额外特性      |      SAI       |      |

## 任务

1. 读懂两篇论文
2. 缺陷检测
3. 自动检测划痕





## 札记

### RGB565

https://blog.csdn.net/byhook/article/details/84262330



### MCU 机器学习

CMSIS-NN

https://community.arm.com/cn/b/blog/posts/cmsis-nn



### TinyML

为了实现这样的目标，TinyML技术应运而生。顾名思义，这就是一种能够让ML模型“变小”的技术。与上文提到的AIoT机器学习的基本范式一样，TinyML也是要在云端收集数据并进行训练，而不同之处则在于训练后模型的优化和部署——为了适应MCU有限的计算资源，TinyML必须对模型进行“深度压缩”，通过模型的蒸馏（Distillation）、量化（Quantization）、编码（Encoding）、编译（Compilation）一系列操作后才能部署到边缘终端上。

![forward (2).jpg](assets/README/6375548478258945981952293.jpg)

　　其中，一些关键的技术包括：

　　蒸馏：是指在训练后通过剪枝（pruning）和知识蒸馏的技术手段，对模型进行更改，以创建更紧凑的表示形式。

　　量化：在模型蒸馏后，通过量化实现以更少位数的数据类型近似表示32位浮点型数据，在可接受的精度损失范围之内减少模型尺寸大小、内存消耗并加快模型推理速度。

　　编码：就是通过更有效的编码方式（如霍夫曼编码）来存储数据，进一步减小模型规模。

　　编译：通过以上方式压缩好的模型，将被编译为可被大多MCU使用的C或C++代码，通过设备上的轻量级网络解释器（如TF Lite和TF Lite Micro）运行。



## 模型部署

https://aijishu.com/a/1060000000099635

实际上是指CNN算法项目从模型训练---->模型导出----->模型转换------>在线部署的一整套流程。目前市面上已经有了很多优秀的开源嵌入式端部署框架，如MNN、TVM、NCNN、MACE等等，这里我们选择MNN作为嵌入式端的部署框架，选取简单的视觉任务MNIST，来跟大家从头到尾讨论这个部署流程：
